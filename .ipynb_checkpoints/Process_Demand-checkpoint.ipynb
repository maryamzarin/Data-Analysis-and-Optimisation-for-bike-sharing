{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f34e1fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9499e324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method returning graph showing how many journeys were started by day of the week\n",
    "\n",
    "# method that takes a string name of a csv file in the same folder and\n",
    "# returns a DF of the csv contents\n",
    "def getDFfromCSV(csvFileName):\n",
    "    weeklyDF = pd.read_csv(csvFileName)\n",
    "    return weeklyDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2596534c",
   "metadata": {},
   "source": [
    "## Method returning a DF of journeys started in this week\n",
    "### Columns ordered by day : \"StartStation Id\", \"StartStation Name\", \"Start Date\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e744fa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toWeeklyStartedDF(weeklyDF):\n",
    "    # New DataFrame from extracted Start Station Data from original data Set\n",
    "    startedJourneys = pd.DataFrame(weeklyDF[[\"StartStation Id\", \"StartStation Name\", \"Start Date\"]])\n",
    "    \n",
    "    # sort the bike rides in chronological order for the first week of January\n",
    "    # format date column into datetime variable\n",
    "    startedJourneys[\"Start Date\"] = pd.to_datetime(startedJourneys[\"Start Date\"], format='%d/%m/%Y %H:%M')\n",
    "    startedJourneys.sort_values(by= \"Start Date\", inplace=True)\n",
    "    \n",
    "    return startedJourneys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5524693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toWeeklyEndedDF(weeklyDF):\n",
    "    # New DataFrame from extracted End Station Data from original data Set\n",
    "    endedJourneys = pd.DataFrame(weeklyDF[[\"EndStation Id\", \"EndStation Name\", \"End Date\"]])\n",
    "    \n",
    "    # sort the bike rides in chronological order for the first week of January\n",
    "    # format date column into datetime variable\n",
    "    endedJourneys[\"End Date\"] = pd.to_datetime(endedJourneys[\"End Date\"], format='%d/%m/%Y %H:%M')\n",
    "    endedJourneys.sort_values(by= \"End Date\", inplace=True)\n",
    "    \n",
    "    return endedJourneys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdd859a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a day and date column\n",
    "def giveDFDateDayNameColumns(startedJourneys, columnName):\n",
    "     # Create a new date and Day Name column that separates data per day\n",
    "    startedJourneys[\"Day/Month\"] = startedJourneys[columnName].apply(lambda x: \"%d/%d/%d\" % (x.day, x.month,x.year))\n",
    "    startedJourneys[\"Day/Month\"] = startedJourneys[columnName].dt.date\n",
    "    startedJourneys[\"Day Name\"] = startedJourneys[columnName].apply(lambda x: \"%a\" % (x.day_name()))\n",
    "    return startedJourneys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efb4b7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demandByTime - bike borrow requests per day\n",
    "def toGroupByDayDF(startedJourneys):\n",
    "    # Create a new column that separeates data per day and counts how many bike borrow requests\n",
    "    startedJourneys = giveDFDateDayNameColumns(startedJourneys, \"Start Date\")\n",
    "    counterDailyJourneyStarts = startedJourneys.groupby([\"Day/Month\"], as_index=False).size()\n",
    "    #counterDailyJourneyStarts.sort_values(by=\"Day/Month\")\n",
    "    \n",
    "    return counterDailyJourneyStarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a78d22a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demandByTime - bike return requests per day\n",
    "def toGroupByDayDFEnd(endedJourneys):\n",
    "    # Create a new column that separeates data per day and counts how many bike return requests\n",
    "    endedJourneys = giveDFDateDayNameColumns(endedJourneys, \"End Date\")\n",
    "    counterDailyJourneyEnds = endedJourneys.groupby([\"Day/Month\"], as_index=False).size()\n",
    "    #counterDailyJourneyStarts.sort_values(by=\"Day/Month\")\n",
    "    \n",
    "    return counterDailyJourneyEnds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c99e103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Journeys started per hour per day starting Monday-Sunday\n",
    "def toGroupByDayByHourDF(startedJourneys):\n",
    "    # Create a new column that separeates data per day and counts how many bike borrow requests\n",
    "    #startedJourneys[\"Day/Month\"] = startedJourneys[\"Start Date\"].apply(lambda x: \"%d/%d %a\" % (x.day, x.month, x.day_name()))\n",
    "    hourlyCountsSeries = startedJourneys.groupby([startedJourneys[\"Start Date\"].dt.weekday.rename(\"Day\"), startedJourneys[\"Start Date\"].dt.hour.rename(\"Hour\")]).size()\n",
    "    #counterDailyJourneyStarts.sort_values(by=\"Day/Month\")\n",
    "    \n",
    "    hourlyCountsDF = pd.DataFrame(hourlyCountsSeries) \n",
    "    hourlyCountsDF = hourlyCountsDF.reset_index(level=0).reset_index()                             \n",
    "    hourlyCountsDF.columns = [\"Day of Week\", \"Hour\", \"Number of Journeys Started\"]                           \n",
    "    \n",
    "    #hourlyCountsDF =hourlyCountsSeries.to_frame('size')\n",
    "    #hourlyCountsSeries = hourlyCountsSeries[\"Start Date\", \"Start Date\", \"StartStation Id\"]\n",
    "    #hourlyCountsDF.index.names = [\"Start Date1\", \"Start Date2\",\"size\"]\n",
    "    #hourlyCountsDF.columns = hourlyCountsDF.columns.droplevel(0)\n",
    "    \n",
    "    #hourlyCountsSeries = hourlyCountsSeries.reset_index(name=\"new name\")\n",
    "    #df = pd.DataFrame(hourlyCountsSeries).reset_index()\n",
    "    #df.columns = ['Day', 'Hour', \"Num Journeys Started\"]\n",
    "    return hourlyCountsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "359f5d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createAllHoursTotalDF(startedJourneys):\n",
    "    # Create a new column that separeates data per day and counts how many bike borrow requests\n",
    "    #startedJourneys[\"Day/Month\"] = startedJourneys[\"Start Date\"].apply(lambda x: \"%d/%d %a\" % (x.day, x.month, x.day_name()))\n",
    "    hourlyCountsSeries = startedJourneys.groupby([startedJourneys[\"Start Date\"].dt.hour.rename(\"Hour\")]).size()\n",
    "    #counterDailyJourneyStarts.sort_values(by=\"Day/Month\")\n",
    "    \n",
    "    hourlyCountsDF = pd.DataFrame(hourlyCountsSeries) \n",
    "    hourlyCountsDF = hourlyCountsDF.reset_index(level=0)                             \n",
    "    hourlyCountsDF.columns = [\"Hour\", \"Total Number of Journeys Started\"]                           \n",
    "    return hourlyCountsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b10de7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the mean demand for each hour Mon - Fri \n",
    "def createAllHoursMonToFriMeanDF(startedJourneys):\n",
    "    # Create a new column that separeates data per day and counts how many bike borrow requests\n",
    "    #startedJourneys[\"Day/Month\"] = startedJourneys[\"Start Date\"].apply(lambda x: \"%d/%d %a\" % (x.day, x.month, x.day_name()))\n",
    "    startedJourneysMonToFri = startedJourneys.loc[startedJourneys[\"Day Name\"].isin([\"'Monday'\",\"'Tuesday'\",\"'Wednesday'\",\"'Thursday'\",\"'Friday'\"])]\n",
    "    #startedJourneysMonToFri = startedJourneys[(startedJourneys[\"Day Name\"]== 'Monday') | (startedJourneys[\"Day Name\"] == 'Tuesday')]\n",
    "    \n",
    "    hourlyCountsSeries = startedJourneysMonToFri.groupby([startedJourneysMonToFri[\"Start Date\"].dt.hour.rename(\"Hour\")]).size()/5\n",
    "    #counterDailyJourneyStarts.sort_values(by=\"Day/Month\")\n",
    "    \n",
    "    hourlyCountsDF = pd.DataFrame(hourlyCountsSeries) \n",
    "    hourlyCountsDF = hourlyCountsDF.reset_index(level=0)                             \n",
    "    hourlyCountsDF.columns = [\"Hour\", \"Total Number of Journeys Started\"]                           \n",
    "    return hourlyCountsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc394ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the mean demand for each hour for the Weekend\n",
    "def createAllHoursSatSunTotalDF(startedJourneys):\n",
    "    # Create a new column that separeates data per day and counts how many bike borrow requests\n",
    "    #startedJourneys[\"Day/Month\"] = startedJourneys[\"Start Date\"].apply(lambda x: \"%d/%d %a\" % (x.day, x.month, x.day_name()))\n",
    "    startedJourneysMonToFri = startedJourneys.loc[~startedJourneys[\"Day Name\"].isin([\"'Monday'\",\"'Tuesday'\",\"'Wednesday'\",\"'Thursday'\",\"'Friday'\"])]\n",
    "    #startedJourneysMonToFri = startedJourneys[(startedJourneys[\"Day Name\"]== 'Monday') | (startedJourneys[\"Day Name\"] == 'Tuesday')]\n",
    "    \n",
    "    hourlyCountsSeries = startedJourneysMonToFri.groupby([startedJourneysMonToFri[\"Start Date\"].dt.hour.rename(\"Hour\")]).size()/2\n",
    "    #counterDailyJourneyStarts.sort_values(by=\"Day/Month\")\n",
    "    \n",
    "    hourlyCountsDF = pd.DataFrame(hourlyCountsSeries) \n",
    "    hourlyCountsDF = hourlyCountsDF.reset_index(level=0)                             \n",
    "    hourlyCountsDF.columns = [\"Hour\", \"Total Number of Journeys Started\"]                           \n",
    "    return hourlyCountsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eeae9e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createAllHoursMeanDF(startedJourneys):\n",
    "    # Create a new column that separeates data per day and counts how many bike borrow requests\n",
    "    #startedJourneys[\"Day/Month\"] = startedJourneys[\"Start Date\"].apply(lambda x: \"%d/%d %a\" % (x.day, x.month, x.day_name()))\n",
    "    hourlyCountsSeries = startedJourneys.groupby([startedJourneys[\"Start Date\"].dt.hour.rename(\"Hour\")]).size()/7\n",
    "    #counterDailyJourneyStarts.sort_values(by=\"Day/Month\")\n",
    "    \n",
    "    hourlyCountsDF = pd.DataFrame(hourlyCountsSeries) \n",
    "    hourlyCountsDF = hourlyCountsDF.reset_index(level=0)                             \n",
    "    hourlyCountsDF.columns = [\"Hour\", \"Average Number of Journeys Started\"]                           \n",
    "    return hourlyCountsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f92c70fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numGainOrLossByStationStart(startedJourneys):\n",
    "    startedDayStationDF = startedJourneys.groupby([\"Day/Month\", \"StartStation Name\",\"StartStation Id\"], as_index=False).size()\n",
    "    \n",
    "    return startedDayStationDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92c49791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numGainOrLossByStationEnd(endedJourneys):\n",
    "    endedDayStationDF = endedJourneys.groupby([\"Day/Month\", \"EndStation Name\", \"EndStation Id\"], as_index=False).size()\n",
    "    \n",
    "    return endedDayStationDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9e37852",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Cleaned. Rides Removed = 463\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rental Id</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Bike Id</th>\n",
       "      <th>End Date</th>\n",
       "      <th>EndStation Id</th>\n",
       "      <th>EndStation Name</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>StartStation Id</th>\n",
       "      <th>StartStation Name</th>\n",
       "      <th>Hire Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94113398</td>\n",
       "      <td>960</td>\n",
       "      <td>6800</td>\n",
       "      <td>2020-01-07 14:07:00</td>\n",
       "      <td>541</td>\n",
       "      <td>Green Park Station, Mayfair</td>\n",
       "      <td>2020-01-07 13:51:00</td>\n",
       "      <td>164</td>\n",
       "      <td>Cleveland Gardens, Bayswater</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94117049</td>\n",
       "      <td>600</td>\n",
       "      <td>8691</td>\n",
       "      <td>2020-01-07 17:06:00</td>\n",
       "      <td>48</td>\n",
       "      <td>Godliman Street, St. Paul's</td>\n",
       "      <td>2020-01-07 16:56:00</td>\n",
       "      <td>323</td>\n",
       "      <td>Clifton Street, Shoreditch</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94110497</td>\n",
       "      <td>540</td>\n",
       "      <td>531</td>\n",
       "      <td>2020-01-07 11:01:00</td>\n",
       "      <td>654</td>\n",
       "      <td>Ashmole Estate, Oval</td>\n",
       "      <td>2020-01-07 10:52:00</td>\n",
       "      <td>624</td>\n",
       "      <td>Courland Grove, Wandsworth Road</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94050449</td>\n",
       "      <td>600</td>\n",
       "      <td>8150</td>\n",
       "      <td>2020-01-04 12:27:00</td>\n",
       "      <td>685</td>\n",
       "      <td>Osiers Road, Wandsworth</td>\n",
       "      <td>2020-01-04 12:17:00</td>\n",
       "      <td>774</td>\n",
       "      <td>Hurlingham Park, Parsons Green</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94019122</td>\n",
       "      <td>1140</td>\n",
       "      <td>15515</td>\n",
       "      <td>2020-01-02 16:31:00</td>\n",
       "      <td>676</td>\n",
       "      <td>Hartington Road, Stockwell</td>\n",
       "      <td>2020-01-02 16:12:00</td>\n",
       "      <td>83</td>\n",
       "      <td>Panton Street, West End</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126333</th>\n",
       "      <td>94067445</td>\n",
       "      <td>360</td>\n",
       "      <td>14461</td>\n",
       "      <td>2020-01-05 13:25:00</td>\n",
       "      <td>183</td>\n",
       "      <td>Riverlight North, Nine Elms</td>\n",
       "      <td>2020-01-05 13:19:00</td>\n",
       "      <td>800</td>\n",
       "      <td>Sopwith Way, Battersea Park</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126334</th>\n",
       "      <td>94105080</td>\n",
       "      <td>1260</td>\n",
       "      <td>16363</td>\n",
       "      <td>2020-01-07 08:50:00</td>\n",
       "      <td>129</td>\n",
       "      <td>Golden Square, Soho</td>\n",
       "      <td>2020-01-07 08:29:00</td>\n",
       "      <td>804</td>\n",
       "      <td>Good's Way, King's Cross</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126335</th>\n",
       "      <td>94056128</td>\n",
       "      <td>780</td>\n",
       "      <td>3351</td>\n",
       "      <td>2020-01-04 16:11:00</td>\n",
       "      <td>376</td>\n",
       "      <td>Millbank Tower, Pimlico</td>\n",
       "      <td>2020-01-04 15:58:00</td>\n",
       "      <td>800</td>\n",
       "      <td>Sopwith Way, Battersea Park</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126336</th>\n",
       "      <td>94115074</td>\n",
       "      <td>420</td>\n",
       "      <td>16831</td>\n",
       "      <td>2020-01-07 15:40:00</td>\n",
       "      <td>695</td>\n",
       "      <td>Islington Green, Angel</td>\n",
       "      <td>2020-01-07 15:33:00</td>\n",
       "      <td>804</td>\n",
       "      <td>Good's Way, King's Cross</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126337</th>\n",
       "      <td>94068357</td>\n",
       "      <td>180</td>\n",
       "      <td>12421</td>\n",
       "      <td>2020-01-05 14:04:00</td>\n",
       "      <td>439</td>\n",
       "      <td>Killick Street, King's Cross</td>\n",
       "      <td>2020-01-05 14:01:00</td>\n",
       "      <td>804</td>\n",
       "      <td>Good's Way, King's Cross</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126338 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Rental Id  Duration  Bike Id            End Date  EndStation Id  \\\n",
       "0        94113398       960     6800 2020-01-07 14:07:00            541   \n",
       "1        94117049       600     8691 2020-01-07 17:06:00             48   \n",
       "2        94110497       540      531 2020-01-07 11:01:00            654   \n",
       "3        94050449       600     8150 2020-01-04 12:27:00            685   \n",
       "4        94019122      1140    15515 2020-01-02 16:31:00            676   \n",
       "...           ...       ...      ...                 ...            ...   \n",
       "126333   94067445       360    14461 2020-01-05 13:25:00            183   \n",
       "126334   94105080      1260    16363 2020-01-07 08:50:00            129   \n",
       "126335   94056128       780     3351 2020-01-04 16:11:00            376   \n",
       "126336   94115074       420    16831 2020-01-07 15:40:00            695   \n",
       "126337   94068357       180    12421 2020-01-05 14:04:00            439   \n",
       "\n",
       "                     EndStation Name          Start Date  StartStation Id  \\\n",
       "0        Green Park Station, Mayfair 2020-01-07 13:51:00              164   \n",
       "1        Godliman Street, St. Paul's 2020-01-07 16:56:00              323   \n",
       "2               Ashmole Estate, Oval 2020-01-07 10:52:00              624   \n",
       "3            Osiers Road, Wandsworth 2020-01-04 12:17:00              774   \n",
       "4         Hartington Road, Stockwell 2020-01-02 16:12:00               83   \n",
       "...                              ...                 ...              ...   \n",
       "126333   Riverlight North, Nine Elms 2020-01-05 13:19:00              800   \n",
       "126334           Golden Square, Soho 2020-01-07 08:29:00              804   \n",
       "126335       Millbank Tower, Pimlico 2020-01-04 15:58:00              800   \n",
       "126336        Islington Green, Angel 2020-01-07 15:33:00              804   \n",
       "126337  Killick Street, King's Cross 2020-01-05 14:01:00              804   \n",
       "\n",
       "                      StartStation Name  Hire Time  \n",
       "0          Cleveland Gardens, Bayswater       16.0  \n",
       "1            Clifton Street, Shoreditch       10.0  \n",
       "2       Courland Grove, Wandsworth Road        9.0  \n",
       "3        Hurlingham Park, Parsons Green       10.0  \n",
       "4               Panton Street, West End       19.0  \n",
       "...                                 ...        ...  \n",
       "126333      Sopwith Way, Battersea Park        6.0  \n",
       "126334         Good's Way, King's Cross       21.0  \n",
       "126335      Sopwith Way, Battersea Park       13.0  \n",
       "126336         Good's Way, King's Cross        7.0  \n",
       "126337         Good's Way, King's Cross        3.0  \n",
       "\n",
       "[126338 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocessData(weekDF):\n",
    "    \"\"\"\n",
    "    preprocessData removes invalid rides and formats the Dates to the datetime type\n",
    "    :param weekDF: a dataframe containg a single week of TfL bike ride data \n",
    "    :return: the same dataframe with invalid rides removed and Start_Date and End_Date columns formatted\n",
    "    \"\"\" \n",
    "    # Type Format the Time Columns in the DataFrame\n",
    "    weekDF[\"Start Date\"] = pd.to_datetime(weekDF[\"Start Date\"], format='%d/%m/%Y %H:%M')\n",
    "    weekDF[\"End Date\"] = pd.to_datetime(weekDF[\"End Date\"], format='%d/%m/%Y %H:%M')\n",
    "    weekDF[\"Hire Time\"]= (weekDF[\"End Date\"] - weekDF[\"Start Date\"]).dt.total_seconds() / 60\n",
    "    \n",
    "    # Remove any rides that start and end at the same station and are less than 3 minutes long\n",
    "    counter = 0\n",
    "    for index,row in weekDF.iterrows():\n",
    "        if (row[\"Hire Time\"]<3) & (row[\"StartStation Name\"]==row[\"EndStation Name\"]):\n",
    "            weekDF = weekDF.drop(labels=index, axis=0)\n",
    "            counter+=1\n",
    "    weekDF= weekDF.reset_index().drop(labels=\"index\", axis=1)        \n",
    "    print(\"Data Cleaned. Rides Removed =\",counter)\n",
    "    return weekDF\n",
    "\n",
    "janWeek1 = '195JourneyDataExtract01Jan2020-07Jan2020.csv'\n",
    "JanW1DF = preprocessData(getDFfromCSV(janWeek1))\n",
    "JanW1DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57bcc3a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rental Id</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Bike Id</th>\n",
       "      <th>End Date</th>\n",
       "      <th>EndStation Id</th>\n",
       "      <th>EndStation Name</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>StartStation Id</th>\n",
       "      <th>StartStation Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94113398</td>\n",
       "      <td>960</td>\n",
       "      <td>6800</td>\n",
       "      <td>07/01/2020 14:07</td>\n",
       "      <td>541</td>\n",
       "      <td>Green Park Station, Mayfair</td>\n",
       "      <td>07/01/2020 13:51</td>\n",
       "      <td>164</td>\n",
       "      <td>Cleveland Gardens, Bayswater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94117049</td>\n",
       "      <td>600</td>\n",
       "      <td>8691</td>\n",
       "      <td>07/01/2020 17:06</td>\n",
       "      <td>48</td>\n",
       "      <td>Godliman Street, St. Paul's</td>\n",
       "      <td>07/01/2020 16:56</td>\n",
       "      <td>323</td>\n",
       "      <td>Clifton Street, Shoreditch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94110497</td>\n",
       "      <td>540</td>\n",
       "      <td>531</td>\n",
       "      <td>07/01/2020 11:01</td>\n",
       "      <td>654</td>\n",
       "      <td>Ashmole Estate, Oval</td>\n",
       "      <td>07/01/2020 10:52</td>\n",
       "      <td>624</td>\n",
       "      <td>Courland Grove, Wandsworth Road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94050449</td>\n",
       "      <td>600</td>\n",
       "      <td>8150</td>\n",
       "      <td>04/01/2020 12:27</td>\n",
       "      <td>685</td>\n",
       "      <td>Osiers Road, Wandsworth</td>\n",
       "      <td>04/01/2020 12:17</td>\n",
       "      <td>774</td>\n",
       "      <td>Hurlingham Park, Parsons Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94019122</td>\n",
       "      <td>1140</td>\n",
       "      <td>15515</td>\n",
       "      <td>02/01/2020 16:31</td>\n",
       "      <td>676</td>\n",
       "      <td>Hartington Road, Stockwell</td>\n",
       "      <td>02/01/2020 16:12</td>\n",
       "      <td>83</td>\n",
       "      <td>Panton Street, West End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126796</th>\n",
       "      <td>94067445</td>\n",
       "      <td>360</td>\n",
       "      <td>14461</td>\n",
       "      <td>05/01/2020 13:25</td>\n",
       "      <td>183</td>\n",
       "      <td>Riverlight North, Nine Elms</td>\n",
       "      <td>05/01/2020 13:19</td>\n",
       "      <td>800</td>\n",
       "      <td>Sopwith Way, Battersea Park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126797</th>\n",
       "      <td>94105080</td>\n",
       "      <td>1260</td>\n",
       "      <td>16363</td>\n",
       "      <td>07/01/2020 08:50</td>\n",
       "      <td>129</td>\n",
       "      <td>Golden Square, Soho</td>\n",
       "      <td>07/01/2020 08:29</td>\n",
       "      <td>804</td>\n",
       "      <td>Good's Way, King's Cross</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126798</th>\n",
       "      <td>94056128</td>\n",
       "      <td>780</td>\n",
       "      <td>3351</td>\n",
       "      <td>04/01/2020 16:11</td>\n",
       "      <td>376</td>\n",
       "      <td>Millbank Tower, Pimlico</td>\n",
       "      <td>04/01/2020 15:58</td>\n",
       "      <td>800</td>\n",
       "      <td>Sopwith Way, Battersea Park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126799</th>\n",
       "      <td>94115074</td>\n",
       "      <td>420</td>\n",
       "      <td>16831</td>\n",
       "      <td>07/01/2020 15:40</td>\n",
       "      <td>695</td>\n",
       "      <td>Islington Green, Angel</td>\n",
       "      <td>07/01/2020 15:33</td>\n",
       "      <td>804</td>\n",
       "      <td>Good's Way, King's Cross</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126800</th>\n",
       "      <td>94068357</td>\n",
       "      <td>180</td>\n",
       "      <td>12421</td>\n",
       "      <td>05/01/2020 14:04</td>\n",
       "      <td>439</td>\n",
       "      <td>Killick Street, King's Cross</td>\n",
       "      <td>05/01/2020 14:01</td>\n",
       "      <td>804</td>\n",
       "      <td>Good's Way, King's Cross</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126801 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Rental Id  Duration  Bike Id          End Date  EndStation Id  \\\n",
       "0        94113398       960     6800  07/01/2020 14:07            541   \n",
       "1        94117049       600     8691  07/01/2020 17:06             48   \n",
       "2        94110497       540      531  07/01/2020 11:01            654   \n",
       "3        94050449       600     8150  04/01/2020 12:27            685   \n",
       "4        94019122      1140    15515  02/01/2020 16:31            676   \n",
       "...           ...       ...      ...               ...            ...   \n",
       "126796   94067445       360    14461  05/01/2020 13:25            183   \n",
       "126797   94105080      1260    16363  07/01/2020 08:50            129   \n",
       "126798   94056128       780     3351  04/01/2020 16:11            376   \n",
       "126799   94115074       420    16831  07/01/2020 15:40            695   \n",
       "126800   94068357       180    12421  05/01/2020 14:04            439   \n",
       "\n",
       "                     EndStation Name        Start Date  StartStation Id  \\\n",
       "0        Green Park Station, Mayfair  07/01/2020 13:51              164   \n",
       "1        Godliman Street, St. Paul's  07/01/2020 16:56              323   \n",
       "2               Ashmole Estate, Oval  07/01/2020 10:52              624   \n",
       "3            Osiers Road, Wandsworth  04/01/2020 12:17              774   \n",
       "4         Hartington Road, Stockwell  02/01/2020 16:12               83   \n",
       "...                              ...               ...              ...   \n",
       "126796   Riverlight North, Nine Elms  05/01/2020 13:19              800   \n",
       "126797           Golden Square, Soho  07/01/2020 08:29              804   \n",
       "126798       Millbank Tower, Pimlico  04/01/2020 15:58              800   \n",
       "126799        Islington Green, Angel  07/01/2020 15:33              804   \n",
       "126800  Killick Street, King's Cross  05/01/2020 14:01              804   \n",
       "\n",
       "                      StartStation Name  \n",
       "0          Cleveland Gardens, Bayswater  \n",
       "1            Clifton Street, Shoreditch  \n",
       "2       Courland Grove, Wandsworth Road  \n",
       "3        Hurlingham Park, Parsons Green  \n",
       "4               Panton Street, West End  \n",
       "...                                 ...  \n",
       "126796      Sopwith Way, Battersea Park  \n",
       "126797         Good's Way, King's Cross  \n",
       "126798      Sopwith Way, Battersea Park  \n",
       "126799         Good's Way, King's Cross  \n",
       "126800         Good's Way, King's Cross  \n",
       "\n",
       "[126801 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getDFfromCSV(janWeek1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d6840b",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f8c9f0e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Cleaned. Rides Removed = 463\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '218JourneyDataExtract10Jun2020-16Jun2020.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_79076\\2907324438.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mjuneWeek2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"218JourneyDataExtract10Jun2020-16Jun2020.csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mjuneW2DF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetDFfromCSV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjuneWeek2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mfebW1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"200JourneyDataExtract05Feb2020-11Feb2020.csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_79076\\4112457137.py\u001b[0m in \u001b[0;36mgetDFfromCSV\u001b[1;34m(csvFileName)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# returns a DF of the csv contents\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetDFfromCSV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsvFileName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mweeklyDF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsvFileName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mweeklyDF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '218JourneyDataExtract10Jun2020-16Jun2020.csv'"
     ]
    }
   ],
   "source": [
    "#Main\n",
    "janWeek1 = '195JourneyDataExtract01Jan2020-07Jan2020.csv'\n",
    "JanW1DF = preprocessData(getDFfromCSV(janWeek1))\n",
    "\n",
    "juneWeek1 = \"217JourneyDataExtract03Jun2020-09Jun2020.csv\"\n",
    "juneW1DF = getDFfromCSV(juneWeek1)\n",
    "\n",
    "juneWeek2 = \"218JourneyDataExtract10Jun2020-16Jun2020.csv\"\n",
    "juneW2DF = getDFfromCSV(juneWeek2)\n",
    "\n",
    "febW1 = \"200JourneyDataExtract05Feb2020-11Feb2020.csv\"\n",
    "febW1DF = preprocessData(getDFfromCSV(febW1))\n",
    "\n",
    "startedJourneys = toWeeklyStartedDF(febW1DF)\n",
    "\n",
    "dayDF = toGroupByDayDF(startedJourneys)\n",
    "hoursInDayDF = toGroupByDayByHourDF(startedJourneys)\n",
    "allHoursTotalDF = createAllHoursTotalDF(startedJourneys)\n",
    "allHoursMeanDF = createAllHoursMeanDF(startedJourneys)\n",
    "JanW1DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35d9dba",
   "metadata": {},
   "source": [
    "# Calculate the average Change in Bike inventory for each station per week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bf34eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using First Week of February which is a regular pre-covid week\n",
    "# End Table stores the number of journeys ended at each station for each day of this week in the \"size\" column\n",
    "endedJourneys = toWeeklyEndedDF(febW1DF)\n",
    "endByDay = toGroupByDayDFEnd(endedJourneys)\n",
    "endTable = numGainOrLossByStationEnd(endedJourneys)\n",
    "endedJourneys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a23831",
   "metadata": {},
   "outputs": [],
   "source": [
    "startTable = numGainOrLossByStationStart(startedJourneys)\n",
    "startTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9bdf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# startTable stores the change in the inventory of bikes for each station each day for this week \n",
    "# size here is the number of journeys started at the station or number of bikes borrowed from the station\n",
    "startTable[\"Change in number of bikes\"] = endTable[\"size\"] - startTable[\"size\"]\n",
    "startTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1f2610",
   "metadata": {},
   "outputs": [],
   "source": [
    "#not useful\n",
    "#numGainOrLossByStationStart(startedJourneys).plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaac8c2",
   "metadata": {},
   "source": [
    "# Find the change in Bike inventory for each station after the AM and PM Peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aa11aa",
   "metadata": {},
   "source": [
    "## AM Peak pre-covid = 8AM, use data for 9AM\n",
    "## PM Peak pre-covid = 5PM, use data for 7PM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ffb007",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For one days data\n",
    "## Find journeys started for each station for each hour\n",
    "## Sum Journeys started until 9am for each station, \n",
    "def journeysEndedBeforeTime(weekDF, timeUntil):\n",
    "    \"\"\"\n",
    "    journeysEndedBeforeTime Sums the journeys ended until a given time, for each station\n",
    "    :param weekDF: a dataframe containg a single week of TfL bike ride data \n",
    "    :param timeUntil: the hour inclusive you want the sum of the number of journeys ended until\n",
    "    :return: a DF giving you the number of journeys ended at each station until the time\n",
    "                [StationID, End Station Name, Total Number of journeys Ended]\n",
    "    \"\"\" \n",
    "    ## Find journeys ended for each station for each hour\n",
    "    endedJourneys = toWeeklyEndedDF(weekDF)\n",
    "    giveDFDateDayNameColumns(endedJourneys, \"End Date\")\n",
    "\n",
    "    endedJourneysWed = endedJourneys.loc[endedJourneys[\"Day Name\"].isin([\"'Wednesday'\"])]\n",
    "\n",
    "    hourlyCountsSeries = endedJourneysWed.groupby([\"EndStation Name\", \"EndStation Id\",endedJourneysWed[\"End Date\"].dt.hour.rename(\"Hour\")]).size()\n",
    "\n",
    "    hourlyCountsDF = pd.DataFrame(hourlyCountsSeries) \n",
    "    hourlyCountsDF = hourlyCountsDF.reset_index(level=0).reset_index()                             \n",
    "    hourlyCountsDF.columns = [ \"EndStation Id\", \"Hour\", \"EndStation Name\",\"Total Number of Journeys Ended\"] \n",
    "\n",
    "    ## Sum journeys ended for each station until 9AM and then do ended-started\n",
    "\n",
    "    endedAt9AMEachStationDF = pd.DataFrame([], columns=[\"Station Name\", \"Journeys Ended by 9AM\"])\n",
    "    \n",
    "    listUniqueStationNames = pd.unique(hourlyCountsDF['EndStation Name'])\n",
    "    stationNamesDF = pd.DataFrame(listUniqueStationNames)\n",
    "    \n",
    "    before9AMDF = hourlyCountsDF.loc[(hourlyCountsDF['Hour'] <= timeUntil)]\n",
    "    before9AMDF= before9AMDF.groupby([\"EndStation Name\",\"EndStation Id\"]).sum()\n",
    "\n",
    "    before9AMDF = before9AMDF.reset_index(level=0).reset_index()                             \n",
    "    before9AMDF= before9AMDF.drop([\"Hour\"], axis=\"columns\")\n",
    "    return before9AMDF\n",
    "endedBefore9AMDF = journeysEndedBeforeTime(febW1DF, 9)\n",
    "endedBefore9AMDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3da427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def journeysStartedBeforeTime(weekDF, timeUntil):\n",
    "    \"\"\"\n",
    "    journeysStartedBeforeTime Sums the journeys started until a given time, for each station\n",
    "    :param weekDF: a dataframe containg a single week of TfL bike ride data \n",
    "    :param timeUntil: the hour inclusive you want the sum of the number of journeys started until\n",
    "    :return: a DF giving you the number of journeys started at each station until the time\n",
    "                [StationID, Start Station Name, Total Number of journeys started]\n",
    "    \"\"\" \n",
    "    ## Find journeys ended for each station for each hour\n",
    "    startedJourneys = toWeeklyStartedDF(weekDF)\n",
    "    giveDFDateDayNameColumns(startedJourneys, \"Start Date\")\n",
    "\n",
    "    startedJourneysWed = startedJourneys.loc[startedJourneys[\"Day Name\"].isin([\"'Wednesday'\"])]\n",
    "\n",
    "    hourlyCountsSeries = startedJourneysWed.groupby(\n",
    "        [\"StartStation Name\", \"StartStation Id\",startedJourneysWed[\"Start Date\"].dt.hour.rename(\"Hour\")]).size()\n",
    "\n",
    "    hourlyCountsDF = pd.DataFrame(hourlyCountsSeries) \n",
    "    hourlyCountsDF = hourlyCountsDF.reset_index(level=0).reset_index()                             \n",
    "    hourlyCountsDF.columns = [ \"StartStation Id\", \"Hour\", \"StartStation Name\",\"Total Number of Journeys Started\"] \n",
    "\n",
    "    ## Sum journeys ended for each station until 9AM and then do ended-started\n",
    "\n",
    "    startedAt9AMEachStationDF = pd.DataFrame([], columns=[\"Station Name\", \"Journeys Started by 9AM\"])\n",
    "    listUniqueStationNames = pd.unique(hourlyCountsDF['StartStation Name'])\n",
    "    stationNamesDF = pd.DataFrame(listUniqueStationNames)\n",
    "\n",
    "    before9AMDF = hourlyCountsDF.loc[(hourlyCountsDF['Hour'] <= timeUntil)]\n",
    "    before9AMDF= before9AMDF.groupby([\"StartStation Name\",\"StartStation Id\"]).sum()\n",
    "\n",
    "    before9AMDF = before9AMDF.reset_index(level=0).reset_index()                             \n",
    "    before9AMDF= before9AMDF.drop([\"Hour\"], axis=\"columns\")\n",
    "    return before9AMDF\n",
    "\n",
    "startedBefore9AMDF = journeysStartedBeforeTime(febW1DF, 9)\n",
    "startedBefore9AMDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccc1d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#joined9AMDF = pd.concat([startedBefore9AMDF, endedBefore9AMDF], axis=1)\n",
    "def mergeEndedAndStartDFByTime(endedBefore9AMDF,startedBefore9AMDF, timeString ):\n",
    "    joined9AMDF = pd.merge(startedBefore9AMDF, endedBefore9AMDF, how='outer', left_on = ['StartStation Name','StartStation Id'], right_on = ['EndStation Name','EndStation Id'])  \n",
    "    joined9AMDF['StartStation Name'] = joined9AMDF['StartStation Name'].fillna(joined9AMDF['EndStation Name'])\n",
    "    joined9AMDF['StartStation Id'] = joined9AMDF['StartStation Id'].fillna(joined9AMDF['EndStation Id'])\n",
    "    \n",
    "    #joined9AMDF= joined9AMDF.drop(['EndStation Name'], axis=\"columns\")\n",
    "    \n",
    "    #joined9AMDF = pd.merge(startedBefore9AMDF, endedBefore9AMDF, how='outer', left_on = 'StartStation Id', right_on = 'EndStation Id')  \n",
    "    \n",
    "    \n",
    "    joined9AMDF= joined9AMDF.drop(['EndStation Name', \"EndStation Id\"], axis=\"columns\")\n",
    "    \n",
    "    joined9AMDF= joined9AMDF.fillna(0)\n",
    "    joined9AMDF[(\"Change In Inventory by \"+timeString)] = joined9AMDF[\"Total Number of Journeys Ended\"] - joined9AMDF[\"Total Number of Journeys Started\"]\n",
    "    \n",
    "    return joined9AMDF\n",
    "\n",
    "def changeInBikeInventoryForTime(weekDF, timeInt, timeString):\n",
    "    endedBefore9AMDF = journeysEndedBeforeTime(weekDF, timeInt)\n",
    "    startedBefore9AMDF = journeysStartedBeforeTime(weekDF, timeInt)\n",
    "    endAndStartedJourneys9AMDF = mergeEndedAndStartDFByTime(endedBefore9AMDF, startedBefore9AMDF, timeString)\n",
    "    return endAndStartedJourneys9AMDF\n",
    "endAndStartedJourneys9AMDF = changeInBikeInventoryForTime(febW1DF, 9, \"9AM\")\n",
    "endAndStartedJourneys9AMDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77701a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "endAndStartedJourneys7PMDF = changeInBikeInventoryForTime(febW1DF, 19, \"7PM\")\n",
    "endAndStartedJourneys7PMDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ad268e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#End of the day \n",
    "endAndStartedJourneys11PMDF = changeInBikeInventoryForTime(febW1DF, 23, \"11PM\")\n",
    "endAndStartedJourneys11PMJUNEDF = changeInBikeInventoryForTime(juneW1DF, 23, \"11PM\")\n",
    "endAndStartedJourneys11PMJUNEDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd6ef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Min Activity after AM Peak\n",
    "endAndStartedJourneys10AMDF = changeInBikeInventoryForTime(febW1DF, 10, \"10AM\")\n",
    "endAndStartedJourneys10AMDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adc7298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e253d158",
   "metadata": {},
   "source": [
    "# Total Activity per day for all stations in a week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98da339",
   "metadata": {},
   "outputs": [],
   "source": [
    "totalActivityPerDayAllStationDF = pd.concat([dayDF,endByDay]).groupby(['Day/Month']).sum().reset_index()\n",
    "totalActivityPerDayAllStationDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acb5e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "totalActivityPerDayAllStationDF = totalActivityPerDayAllStationDF.sort_values(by = ['Day/Month'])\n",
    "totalActivityPerDayAllStationDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf39aec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#totalActivityPerDayAllStationDF[\"Day/Month\"] = pd.to_datetime(totalActivityPerDayAllStationDF[\"Day/Month\"], format= '%d/%m/%Y')\n",
    "#endedJourneys[\"End Date\"] = pd.to_datetime(endedJourneys[\"End Date\"], format='%d/%m/%Y %H:%M')\n",
    "\n",
    "\n",
    "#totalActivityPerDayAllStationDF[\"Date\"] = totalActivityPerDayAllStationDF[\"Day/Month\"].apply(lambda x: \"%d/%d\" % (x.day, x.month))\n",
    "totalActivityPerDayAllStationDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75763620",
   "metadata": {},
   "source": [
    "# Graphs and Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d8b0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "allHoursTotalDFTemp = allHoursTotalDF.drop(\"Hour\", axis = 'columns')\n",
    "allHoursTotalDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7e44f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The value for 0 is the number of rides between 00:00 and 01:00, the value for 1 is the number of rides between \n",
    "# 01:00 and 02:00 and so on\n",
    "xaxisLabels =[]\n",
    "for i in range(0,24):\n",
    "    xaxisLabels.append(i)\n",
    "allHoursTotalDFTemp.plot(kind=\"line\", figsize=(15,10), \n",
    "                         xlabel= \"Time in 24hr\",\n",
    "                         ylabel=\"Total Number of Journeys Started\", \n",
    "                         xticks = xaxisLabels,\n",
    "                         title = \"Average no. journeys started every hour Monday to Sunday\",\n",
    "                         grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07235083",
   "metadata": {},
   "outputs": [],
   "source": [
    "startedJourneysFeb = toWeeklyStartedDF(febW1DF)\n",
    "startedJourneysFeb = giveDFDateDayNameColumns(startedJourneysFeb, \"Start Date\")\n",
    "startedJourneysFeb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e02eb5",
   "metadata": {},
   "source": [
    "## Average of Journeys started each hour Mon-Fri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df247e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "monToFriHourly = createAllHoursMonToFriMeanDF(startedJourneysFeb)\n",
    "\n",
    "startedJourneysJune1 = toWeeklyStartedDF(juneW1DF)\n",
    "startedJourneysJune1 = giveDFDateDayNameColumns(startedJourneysJune1, \"Start Date\")\n",
    "janFebJuneMonToFriTotalHourlyDF = monToFriHourly.drop(\"Total Number of Journeys Started\", axis=\"columns\")\n",
    "\n",
    "janFebJuneMonToFriTotalHourlyDF[\"Pre-Covid Week (First Week of Feb)\"] = createAllHoursMonToFriMeanDF(startedJourneysFeb)[\"Total Number of Journeys Started\"]\n",
    "janFebJuneMonToFriTotalHourlyDF[\"Lockdown Week (First Week of June)\"] = createAllHoursMonToFriMeanDF(startedJourneysJune1)[\"Total Number of Journeys Started\"]\n",
    "janFebJuneMonToFriTotalHourlyDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59be2b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The value for 0 is the number of rides between 00:00 and 01:00, the value for 1 is the number of rides between \n",
    "# 01:00 and 02:00 and so on\n",
    "xaxisLabels =[]\n",
    "for i in range(0,24):\n",
    "    xaxisLabels.append(i)\n",
    "janFebJuneMonToFriTotalHourlyDF = janFebJuneMonToFriTotalHourlyDF.drop(\"Hour\", axis=\"columns\")\n",
    "janFebJuneMonToFriTotalHourlyDF.plot(kind=\"line\", figsize=(15,10), \n",
    "                         xlabel= \"Time in 24hr\",\n",
    "                         ylabel=\"Total Number of Journeys Started\", \n",
    "                         xticks = xaxisLabels,\n",
    "                         title = \"Average no. of rides started for each hour across all stations Monday to Friday\",\n",
    "                         grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5ba0ab",
   "metadata": {},
   "source": [
    "## Average journeys started each hour Sat and Sunday average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed521e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "createAllHoursSatSunTotalDF\n",
    "\n",
    "monToFriHourly = createAllHoursSatSunTotalDF(startedJourneysFeb)\n",
    "\n",
    "startedJourneysJune1 = toWeeklyStartedDF(juneW1DF)\n",
    "startedJourneysJune1 = giveDFDateDayNameColumns(startedJourneysJune1, \"Start Date\")\n",
    "janFebJuneSatSunTotalHourlyDF = monToFriHourly.drop(\"Total Number of Journeys Started\", axis=\"columns\")\n",
    "\n",
    "janFebJuneSatSunTotalHourlyDF[\"Pre-Covid Week (First Week of Feb)\"] = createAllHoursSatSunTotalDF(startedJourneysFeb)[\"Total Number of Journeys Started\"]\n",
    "janFebJuneSatSunTotalHourlyDF[\"Lockdown Week (First Week of June)\"] = createAllHoursSatSunTotalDF(startedJourneysJune1)[\"Total Number of Journeys Started\"]\n",
    "janFebJuneSatSunTotalHourlyDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e92251",
   "metadata": {},
   "outputs": [],
   "source": [
    "janFebJuneSatSunTotalHourlyDF = janFebJuneSatSunTotalHourlyDF.drop(\"Hour\", axis=\"columns\")\n",
    "janFebJuneSatSunTotalHourlyDF.plot(kind=\"line\", figsize=(15,10), \n",
    "                         xlabel= \"Time in 24hr\",\n",
    "                         ylabel=\"Total Number of Journeys Started\", \n",
    "                         xticks = xaxisLabels,\n",
    "                         title = \"Average no. of rides started for each hour across all stations for the weekend\",\n",
    "                         grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a033b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b8674b",
   "metadata": {},
   "outputs": [],
   "source": [
    "startedJourneys = toWeeklyStartedDF(febW1DF)\n",
    "allHoursTotalDF = createAllHoursTotalDF(startedJourneys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fe892a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "allHoursMeanDF.plot(kind=\"line\", figsize=(15,10),xlabel= \"Time in 24hr\", ylabel=\"Mean Number of Journeys Started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7076f574",
   "metadata": {},
   "outputs": [],
   "source": [
    "hoursInDayDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91368dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(\"imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8246a815",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plotHoursInDayForWeek(weekDF, graphTitle):\n",
    "    startedJourneys = toWeeklyStartedDF(weekDF)\n",
    "    hoursInDayDF = toGroupByDayByHourDF(startedJourneys)\n",
    "    xaxisLabels =[]\n",
    "    days=[\"Mon\",\"Tue\",\"Wed\",\"Thur\",\"Fri\",\"Sat\",\"Sun\",\"\"]\n",
    "    xaxisLabels2=[]\n",
    "    for i in range(0,8):\n",
    "        #xaxisLabels2.append(days[i])\n",
    "        xaxisLabels.append(i*24)\n",
    "    hoursInDayDFTemp = hoursInDayDF.drop([\"Day of Week\", \"Hour\"], axis='columns')    \n",
    "    ax= hoursInDayDFTemp.plot(kind=\"line\", figsize=(15,10),\n",
    "                      xticks=xaxisLabels,\n",
    "                      xlabel= \"Hour of the Week\", \n",
    "                      ylabel=\"Total Number of Journeys Started\",\n",
    "                      title=graphTitle,\n",
    "                      grid = True)\n",
    "    ax.set_xticklabels(days)\n",
    "    plt.show()   \n",
    "    return hoursInDayDFTemp\n",
    "plotHoursInDayForWeek(febW1DF, \"Number of journeys started for each hour of the first week of February 2020\")   \n",
    "plotHoursInDayForWeek(juneW1DF, \"Number of journeys started for each hour of the first week of June 2020\")   \n",
    "plotHoursInDayForWeek(JanW1DF, \"Number of journeys started for each hour of the first week of January 2020\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a43ec83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dayDF.plot(kind=\"line\", figsize=(15,10), ylabel=\"Total Number of Journeys Started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f3c3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dayDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff73ac4",
   "metadata": {},
   "source": [
    "## GeoPandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c029538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f596e429",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import geopandas as gpd\n",
    "#from geopandas import GeoDataFrame\n",
    "#from shapely.geometry import Point\n",
    "\n",
    "\n",
    "print(\"imported\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
